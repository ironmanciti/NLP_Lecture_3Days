{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a001ecab",
   "metadata": {},
   "source": [
    "# ë¬¸ì¥ ë²¡í„°í™”: BOW, TF-IDF vs ì„ë² ë”©\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- BOW (Bag of Words) ë²¡í„°í™” ë°©ë²• ì´í•´\n",
    "- TF-IDF ë²¡í„°í™” ë°©ë²• ì´í•´\n",
    "- TF-IDF ë²¡í„° ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚° (cosine_similarity)\n",
    "- Sentence Transformer ì„ë² ë”© ë°©ë²• ì´í•´\n",
    "- ì„ë² ë”© ë²¡í„° ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "- ë‘ ë°©ì‹ì˜ ì°¨ì´ì  ì´í•´ (ë‹¨ì–´ ë§¤ì¹­ vs ì˜ë¯¸ ìœ ì‚¬ë„)\n",
    "\n",
    "## í•™ìŠµ ë‚´ìš©\n",
    "1. BOW (Bag of Words) ë²¡í„°í™”\n",
    "2. TF-IDF ë²¡í„°í™” ë° ìœ ì‚¬ë„ ê³„ì‚°\n",
    "3. Sentence Transformer ì„ë² ë”© ë° ìœ ì‚¬ë„ ê³„ì‚°\n",
    "4. ë°©ë²•ë¡  ë¹„êµ: ë‹¨ì–´ ë§¤ì¹­ vs ì˜ë¯¸ ìœ ì‚¬ë„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4429fbb",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. ë°ì´í„° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d7e017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ê¸ˆìœµ ë‰´ìŠ¤ ì˜ˆì‹œ ë°ì´í„°\n",
    "finance_news = [\n",
    "    \"ì‚¼ì„±ì „ì 3ë¶„ê¸° ì˜ì—…ì´ìµ ê¸‰ë“±, ì‚¬ìƒìµœê³  ì‹¤ì  ê¸°ëŒ€\",\n",
    "    \"ì½”ìŠ¤í”¼ í•˜ë½ì„¸ ì§€ì†, ì™¸êµ­ì¸ ìˆœë§¤ë„ í™•ëŒ€ì— ìš°ë ¤\",\n",
    "    \"ë°˜ë„ì²´ ì‹œì¥ ì„±ì¥ì„¸ ì§€ì†, ë©”ëª¨ë¦¬ ë°˜ë„ì²´ ìˆ˜ìš” ì¦ê°€\",\n",
    "    \"ì‚¼ì„±ì „ì ì£¼ê°€ ìƒìŠ¹, ì‹¤ì  í˜¸ì¡° ì „ë§ ë‚™ê´€\",\n",
    "    \"ê¸ˆë¦¬ ì¸ìƒ ìš°ë ¤ë¡œ ì£¼ì‹ ì‹œì¥ í•˜ë½\"\n",
    "]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ê¸ˆìœµ ë‰´ìŠ¤ ë°ì´í„°\")\n",
    "print(\"=\" * 80)\n",
    "for i, news in enumerate(finance_news, 1):\n",
    "    print(f\"{i}. {news}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79f4705",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. BOW (Bag of Words) ë²¡í„°í™”\n",
    "\n",
    "**BOWì˜ íŠ¹ì§•:**\n",
    "- ë‹¨ì–´ì˜ ìˆœì„œë¥¼ ë¬´ì‹œí•˜ê³  ë‹¨ì–´ ë¹ˆë„ë§Œ ê³ ë ¤\n",
    "- í¬ì†Œ ë²¡í„°(Sparse Vector) ìƒì„±\n",
    "- ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„\n",
    "- ì˜ë¯¸ì  ìœ ì‚¬ë„ íŒŒì•… ì–´ë ¤ì›€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf69f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[BOW - Bag of Words ë²¡í„°í™”]\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# CountVectorizer ê°ì²´ ìƒì„±\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# ë¬¸ì¥ë“¤ì„ ë²¡í„°ë¡œ ë³€í™˜\n",
    "bow_features = count_vectorizer.fit_transform(finance_news)\n",
    "bow_array = bow_features.toarray()\n",
    "\n",
    "# ë‹¨ì–´ ëª©ë¡\n",
    "feature_names = count_vectorizer.get_feature_names_out()\n",
    "\n",
    "print(f\"\\në¬¸ì„œ ìˆ˜: {bow_features.shape[0]}\")\n",
    "print(f\"ë‹¨ì–´ ìˆ˜: {bow_features.shape[1]}\")\n",
    "print(f\"\\në‹¨ì–´ ëª©ë¡ (ì¼ë¶€): {list(feature_names[:15])}...\")\n",
    "\n",
    "# DataFrameìœ¼ë¡œ ì‹œê°í™”\n",
    "df_bow = pd.DataFrame(\n",
    "    bow_array, \n",
    "    columns=feature_names, \n",
    "    index=[f\"ë‰´ìŠ¤{i+1}\" for i in range(len(finance_news))]\n",
    ")\n",
    "print(\"\\n[BOW ë²¡í„° í–‰ë ¬]\")\n",
    "print(df_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f342a0",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. TF-IDF ë²¡í„°í™” ë° ìœ ì‚¬ë„ ê³„ì‚°\n",
    "\n",
    "**TF-IDFì˜ íŠ¹ì§•:**\n",
    "- ë‹¨ì–´ì˜ ì¤‘ìš”ë„ë¥¼ ë¬¸ì„œ ë‚´ ë¹ˆë„ì™€ ì „ì²´ ë¬¸ì„œì—ì„œì˜ í¬ê·€ë„ë¥¼ ê³ ë ¤\n",
    "- BOWë³´ë‹¤ ì˜ë¯¸ ìˆëŠ” ê°€ì¤‘ì¹˜ ë¶€ì—¬\n",
    "- ì—¬ì „íˆ í¬ì†Œ ë²¡í„°ì´ì§€ë§Œ BOWë³´ë‹¤ ì •ë³´ëŸ‰ì´ ë§ìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b77e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[TF-IDF ë²¡í„°í™”]\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# TfidfVectorizer ê°ì²´ ìƒì„±\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# ë¬¸ì¥ë“¤ì„ TF-IDF ë²¡í„°ë¡œ ë³€í™˜\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(finance_news)\n",
    "tfidf_array = tfidf_features.toarray()\n",
    "\n",
    "# ë‹¨ì–´ ëª©ë¡\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "print(f\"\\në¬¸ì„œ ìˆ˜: {tfidf_features.shape[0]}\")\n",
    "print(f\"ë‹¨ì–´ ìˆ˜: {tfidf_features.shape[1]}\")\n",
    "\n",
    "# DataFrameìœ¼ë¡œ ì‹œê°í™”\n",
    "df_tfidf = pd.DataFrame(\n",
    "    tfidf_array, \n",
    "    columns=tfidf_feature_names, \n",
    "    index=[f\"ë‰´ìŠ¤{i+1}\" for i in range(len(finance_news))]\n",
    ")\n",
    "print(\"\\n[TF-IDF ë²¡í„° í–‰ë ¬]\")\n",
    "print(df_tfidf.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca00faf",
   "metadata": {},
   "source": [
    "### 3.1 TF-IDF ë²¡í„° ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚° (cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3cc895",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[TF-IDF ë²¡í„° ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚° - cosine_similarity]\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# TF-IDF ë²¡í„° ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "tfidf_similarity = cosine_similarity(tfidf_features)\n",
    "\n",
    "# ìœ ì‚¬ë„ í–‰ë ¬ì„ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "df_tfidf_sim = pd.DataFrame(\n",
    "    tfidf_similarity,\n",
    "    index=[f\"ë‰´ìŠ¤{i+1}\" for i in range(len(finance_news))],\n",
    "    columns=[f\"ë‰´ìŠ¤{i+1}\" for i in range(len(finance_news))]\n",
    ")\n",
    "print(\"\\n[TF-IDF ê¸°ë°˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ í–‰ë ¬]\")\n",
    "print(df_tfidf_sim.round(3))\n",
    "\n",
    "# ë‰´ìŠ¤ ìŒë³„ ìœ ì‚¬ë„ ì¶œë ¥\n",
    "print(\"\\n[ë‰´ìŠ¤ ìŒë³„ ìœ ì‚¬ë„]\")\n",
    "for i in range(len(finance_news)):\n",
    "    for j in range(i+1, len(finance_news)):\n",
    "        sim = tfidf_similarity[i][j]\n",
    "        print(f\"  ë‰´ìŠ¤{i+1} vs ë‰´ìŠ¤{j+1}: {sim:.4f}\")\n",
    "        print(f\"    '{finance_news[i]}'\")\n",
    "        print(f\"    '{finance_news[j]}'\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b995e",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Sentence Transformer ì„ë² ë”© ë° ìœ ì‚¬ë„ ê³„ì‚°\n",
    "\n",
    "**ì„ë² ë”©ì˜ íŠ¹ì§•:**\n",
    "- ë¬¸ì¥ ì „ì²´ë¥¼ ê³ ì • í¬ê¸°ì˜ ë°€ì§‘ ë²¡í„°(Dense Vector)ë¡œ ë³€í™˜\n",
    "- ë¬¸ë§¥ê³¼ ì˜ë¯¸ë¥¼ ì´í•´í•˜ì—¬ ìœ ì‚¬í•œ ì˜ë¯¸ì˜ ë¬¸ì¥ì€ ìœ ì‚¬í•œ ë²¡í„° ìƒì„±\n",
    "- ë‹¨ì–´ ìˆœì„œì™€ ë¬¸ë§¥ì„ ê³ ë ¤\n",
    "- ê³„ì‚° ë¹„ìš©ì´ ë†’ì§€ë§Œ ì •í™•ë„ê°€ ë†’ìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1110377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[Sentence Transformer ì„ë² ë”©]\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# KURE-v1 ëª¨ë¸ ë¡œë“œ (í•œêµ­ì–´ íŠ¹í™”)\n",
    "print(\"\\nì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "model = SentenceTransformer(\"nlpai-lab/KURE-v1\")\n",
    "print(\"âœ“ KURE-v1 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (í•œêµ­ì–´ íŠ¹í™” ë¬¸ì¥ ì„ë² ë”© ëª¨ë¸)\")\n",
    "\n",
    "# ë¬¸ì¥ë“¤ì„ ë²¡í„°ë¡œ ë³€í™˜\n",
    "embeddings = model.encode(finance_news)\n",
    "\n",
    "print(f\"\\nì„ë² ë”© ì°¨ì›: {embeddings.shape}\")\n",
    "print(f\"  - ë¬¸ì¥ ìˆ˜: {embeddings.shape[0]}\")\n",
    "print(f\"  - ë²¡í„° ì°¨ì›: {embeddings.shape[1]}\")\n",
    "\n",
    "# ì²« ë²ˆì§¸ ë¬¸ì¥ì˜ ì„ë² ë”© ë²¡í„° ì¼ë¶€ í™•ì¸\n",
    "print(f\"\\nì²« ë²ˆì§¸ ë‰´ìŠ¤ ì„ë² ë”© ë²¡í„° (ì²˜ìŒ 10ê°œ ê°’):\")\n",
    "print(embeddings[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23c566c",
   "metadata": {},
   "source": [
    "### 4.1 ì„ë² ë”© ë²¡í„° ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d226ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[ì„ë² ë”© ë²¡í„° ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°]\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ë°©ë²• 1: model.similarity() ì‚¬ìš©\n",
    "embedding_similarity_model = model.similarity(embeddings, embeddings)\n",
    "\n",
    "# ë°©ë²• 2: cosine_similarity() ì§ì ‘ ì‚¬ìš© (ë™ì¼í•œ ê²°ê³¼)\n",
    "embedding_similarity_cosine = cosine_similarity(embeddings)\n",
    "\n",
    "print(\"\\n[ë°©ë²• 1: model.similarity() ì‚¬ìš©]\")\n",
    "df_embed_sim_model = pd.DataFrame(\n",
    "    embedding_similarity_model.numpy(),\n",
    "    index=[f\"ë‰´ìŠ¤{i+1}\" for i in range(len(finance_news))],\n",
    "    columns=[f\"ë‰´ìŠ¤{i+1}\" for i in range(len(finance_news))]\n",
    ")\n",
    "print(df_embed_sim_model.round(3))\n",
    "\n",
    "print(\"\\n[ë°©ë²• 2: cosine_similarity() ì§ì ‘ ì‚¬ìš©]\")\n",
    "df_embed_sim_cosine = pd.DataFrame(\n",
    "    embedding_similarity_cosine,\n",
    "    index=[f\"ë‰´ìŠ¤{i+1}\" for i in range(len(finance_news))],\n",
    "    columns=[f\"ë‰´ìŠ¤{i+1}\" for i in range(len(finance_news))]\n",
    ")\n",
    "print(df_embed_sim_cosine.round(3))\n",
    "\n",
    "print(\"\\nğŸ’¡ ë‘ ë°©ë²• ëª¨ë‘ ë™ì¼í•œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤!\")\n",
    "\n",
    "# ë‰´ìŠ¤ ìŒë³„ ìœ ì‚¬ë„ ì¶œë ¥\n",
    "print(\"\\n[ë‰´ìŠ¤ ìŒë³„ ìœ ì‚¬ë„]\")\n",
    "for i in range(len(finance_news)):\n",
    "    for j in range(i+1, len(finance_news)):\n",
    "        sim = embedding_similarity_cosine[i][j]\n",
    "        print(f\"  ë‰´ìŠ¤{i+1} vs ë‰´ìŠ¤{j+1}: {sim:.4f}\")\n",
    "        print(f\"    '{finance_news[i]}'\")\n",
    "        print(f\"    '{finance_news[j]}'\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f661b4",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. ë°©ë²•ë¡  ë¹„êµ: ë‹¨ì–´ ë§¤ì¹­ vs ì˜ë¯¸ ìœ ì‚¬ë„\n",
    "\n",
    "### 5.1 TF-IDFì™€ ì„ë² ë”©ì˜ ì°¨ì´ì  ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cca631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"[TF-IDF vs ì„ë² ë”©: ë‹¨ì–´ ë§¤ì¹­ vs ì˜ë¯¸ ìœ ì‚¬ë„ ë¹„êµ]\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: ì˜ë¯¸ëŠ” ê°™ì§€ë§Œ ë‹¨ì–´ê°€ ë‹¤ë¥¸ ë¬¸ì¥ë“¤\n",
    "test_cases = [\n",
    "    {\n",
    "        'name': 'ì˜ë¯¸ ë™ì¼, ë‹¨ì–´ ë‹¤ë¦„',\n",
    "        'text1': 'ì‚¼ì„±ì „ì ì£¼ê°€ê°€ ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤',\n",
    "        'text2': 'ì‚¼ì„±ì „ì ì£¼ì‹ ê°€ê²©ì´ ì˜¬ëìŠµë‹ˆë‹¤'  # ì˜ë¯¸ëŠ” ê°™ì§€ë§Œ ë‹¨ì–´ê°€ ë‹¤ë¦„\n",
    "    },\n",
    "    {\n",
    "        'name': 'ì˜ë¯¸ ìœ ì‚¬, í‘œí˜„ ë‹¤ë¦„',\n",
    "        'text1': 'ì£¼ê°€ ìƒìŠ¹ ì‹¤ì  í˜¸ì¡° ì „ë§ ë‚™ê´€',\n",
    "        'text2': 'ì£¼ì‹ ê°€ê²© ì¦ê°€ ì‹¤ì  ì¢‹ìŒ ì „ë§ ê¸ì •ì '  # ì˜ë¯¸ ìœ ì‚¬í•˜ì§€ë§Œ í‘œí˜„ ë‹¤ë¦„\n",
    "    },\n",
    "    {\n",
    "        'name': 'ì˜ë¯¸ ë‹¤ë¦„',\n",
    "        'text1': 'ì‚¼ì„±ì „ì ì£¼ê°€ ìƒìŠ¹',\n",
    "        'text2': 'ì½”ìŠ¤í”¼ ì§€ìˆ˜ í•˜ë½'  # ì™„ì „íˆ ë‹¤ë¥¸ ì˜ë¯¸\n",
    "    },\n",
    "    {\n",
    "        'name': 'ë‹¨ì–´ ì¼ë¶€ ê²¹ì¹¨',\n",
    "        'text1': 'ë°˜ë„ì²´ ì‹œì¥ ì„±ì¥',\n",
    "        'text2': 'ë°˜ë„ì²´ ìˆ˜ìš” ì¦ê°€'  # ì¼ë¶€ ë‹¨ì–´ ê²¹ì¹¨\n",
    "    }\n",
    "]\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "results = []\n",
    "\n",
    "for case in test_cases:\n",
    "    text1 = case['text1']\n",
    "    text2 = case['text2']\n",
    "    \n",
    "    # === TF-IDF ë°©ì‹ ===\n",
    "    tfidf_test = TfidfVectorizer()\n",
    "    tfidf_vectors = tfidf_test.fit_transform([text1, text2])\n",
    "    tfidf_sim = cosine_similarity(tfidf_vectors[0:1], tfidf_vectors[1:2])[0][0]\n",
    "    \n",
    "    # ê³µí†µ ë‹¨ì–´ í™•ì¸\n",
    "    words1 = set(text1.split())\n",
    "    words2 = set(text2.split())\n",
    "    common_words = words1.intersection(words2)\n",
    "    \n",
    "    # === ì„ë² ë”© ë°©ì‹ ===\n",
    "    emb_vectors = model.encode([text1, text2])\n",
    "    emb_sim = cosine_similarity([emb_vectors[0]], [emb_vectors[1]])[0][0]\n",
    "    \n",
    "    results.append({\n",
    "        'ì¼€ì´ìŠ¤': case['name'],\n",
    "        'ë¬¸ì¥1': text1,\n",
    "        'ë¬¸ì¥2': text2,\n",
    "        'ê³µí†µë‹¨ì–´': ', '.join(common_words) if common_words else 'ì—†ìŒ',\n",
    "        'TF-IDF_ìœ ì‚¬ë„': tfidf_sim,\n",
    "        'ì„ë² ë”©_ìœ ì‚¬ë„': emb_sim,\n",
    "        'ì°¨ì´': emb_sim - tfidf_sim\n",
    "    })\n",
    "    \n",
    "    # ìƒì„¸ ì¶œë ¥\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"[ì¼€ì´ìŠ¤: {case['name']}]\")\n",
    "    print(f\"  ë¬¸ì¥1: {text1}\")\n",
    "    print(f\"  ë¬¸ì¥2: {text2}\")\n",
    "    print(f\"  ê³µí†µ ë‹¨ì–´: {', '.join(common_words) if common_words else 'ì—†ìŒ'}\")\n",
    "    print(f\"\\n  TF-IDF ìœ ì‚¬ë„: {tfidf_sim:.4f} {'(ë‹¨ì–´ ë§¤ì¹­ ì¤‘ì‹¬)' if tfidf_sim < 0.3 else '(ë‹¨ì–´ ê²¹ì¹¨)'}\")\n",
    "    print(f\"  ì„ë² ë”© ìœ ì‚¬ë„: {emb_sim:.4f} {'(ì˜ë¯¸ ìœ ì‚¬ë„ ì¤‘ì‹¬)' if emb_sim > 0.5 else '(ì˜ë¯¸ ë‹¤ë¦„)'}\")\n",
    "    print(f\"  ì°¨ì´: {emb_sim - tfidf_sim:+.4f}\")\n",
    "    \n",
    "    # í•´ì„\n",
    "    if tfidf_sim < 0.3 and emb_sim > 0.5:\n",
    "        print(f\"\\n  ğŸ’¡ í•´ì„: ë‹¨ì–´ê°€ ë‹¤ë¥´ì§€ë§Œ ì˜ë¯¸ê°€ ìœ ì‚¬ â†’ TF-IDFëŠ” ë‚®ê²Œ, ì„ë² ë”©ì€ ë†’ê²Œ í‰ê°€\")\n",
    "    elif tfidf_sim > 0.3 and emb_sim < 0.5:\n",
    "        print(f\"\\n  ğŸ’¡ í•´ì„: ë‹¨ì–´ëŠ” ê²¹ì¹˜ì§€ë§Œ ì˜ë¯¸ê°€ ë‹¤ë¦„ â†’ TF-IDFëŠ” ë†’ê²Œ, ì„ë² ë”©ì€ ë‚®ê²Œ í‰ê°€\")\n",
    "    print()\n",
    "\n",
    "# ê²°ê³¼ ìš”ì•½ í…Œì´ë¸”\n",
    "print(\"=\" * 80)\n",
    "print(\"[ê²°ê³¼ ìš”ì•½]\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\n[ìƒì„¸ ê²°ê³¼]\")\n",
    "print(df_results[['ì¼€ì´ìŠ¤', 'TF-IDF_ìœ ì‚¬ë„', 'ì„ë² ë”©_ìœ ì‚¬ë„', 'ì°¨ì´']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb9ad1b",
   "metadata": {},
   "source": [
    "### 5.2 í•µì‹¬ ì°¨ì´ì  ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df6e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[í•µì‹¬ ì°¨ì´ì  ìš”ì•½]\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "comparison_data = {\n",
    "    'íŠ¹ì„±': [\n",
    "        'ë²¡í„° íƒ€ì…',\n",
    "        'ë²¡í„° ì°¨ì›',\n",
    "        'ìœ ì‚¬ë„ ê¸°ì¤€',\n",
    "        'ë‹¨ì–´ ìˆœì„œ ê³ ë ¤',\n",
    "        'ê³„ì‚° ì†ë„',\n",
    "        'ì˜ë¯¸ ì´í•´',\n",
    "        'ì£¼ìš” í™œìš© ë¶„ì•¼'\n",
    "    ],\n",
    "    'TF-IDF': [\n",
    "        'í¬ì†Œ ë²¡í„° (Sparse)',\n",
    "        'ì–´íœ˜ í¬ê¸°ì— ë”°ë¼ ê°€ë³€',\n",
    "        'ë‹¨ì–´ ë§¤ì¹­ ì¤‘ì‹¬',\n",
    "        'âŒ ë¬´ì‹œ',\n",
    "        'âš¡ ë§¤ìš° ë¹ ë¦„',\n",
    "        'ì œí•œì  (ë¹ˆë„ ê¸°ë°˜)',\n",
    "        'í‚¤ì›Œë“œ ì¶”ì¶œ, ë¬¸ì„œ ë¶„ë¥˜'\n",
    "    ],\n",
    "    'ì„ë² ë”©': [\n",
    "        'ë°€ì§‘ ë²¡í„° (Dense)',\n",
    "        'ê³ ì • (1024ì°¨ì›)',\n",
    "        'ì˜ë¯¸ ìœ ì‚¬ë„ ì¤‘ì‹¬',\n",
    "        'âœ… ê³ ë ¤',\n",
    "        'ğŸŒ ëŠë¦¼',\n",
    "        'ìš°ìˆ˜ (ë¬¸ë§¥ ê¸°ë°˜)',\n",
    "        'ìœ ì‚¬ë„ ê²€ìƒ‰, ê°ì„± ë¶„ì„'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\")\n",
    "print(df_comparison.to_string(index=False))\n",
    "\n",
    "print(\"\"\"\n",
    "\\n[í•µì‹¬ ì •ë¦¬]\n",
    "\n",
    "1. TF-IDF (ë‹¨ì–´ ë§¤ì¹­ ì¤‘ì‹¬)\n",
    "   âœ“ ë‹¨ì–´ê°€ ê²¹ì¹˜ë©´ ìœ ì‚¬ë„ ë†’ìŒ\n",
    "   âœ— ë‹¨ì–´ê°€ ë‹¤ë¥´ë©´ ìœ ì‚¬ë„ ë‚®ìŒ (ì˜ë¯¸ê°€ ê°™ì•„ë„)\n",
    "   â†’ \"ì£¼ê°€ ìƒìŠ¹\" vs \"ì£¼ì‹ ê°€ê²© ì¦ê°€\" â†’ ë‚®ì€ ìœ ì‚¬ë„\n",
    "\n",
    "2. ì„ë² ë”© (ì˜ë¯¸ ìœ ì‚¬ë„ ì¤‘ì‹¬)\n",
    "   âœ“ ì˜ë¯¸ê°€ ê°™ìœ¼ë©´ ìœ ì‚¬ë„ ë†’ìŒ (ë‹¨ì–´ê°€ ë‹¬ë¼ë„)\n",
    "   âœ— ì˜ë¯¸ê°€ ë‹¤ë¥´ë©´ ìœ ì‚¬ë„ ë‚®ìŒ (ë‹¨ì–´ê°€ ê²¹ì³ë„)\n",
    "   â†’ \"ì£¼ê°€ ìƒìŠ¹\" vs \"ì£¼ì‹ ê°€ê²© ì¦ê°€\" â†’ ë†’ì€ ìœ ì‚¬ë„\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217ae6ba",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. í•™ìŠµ ì •ë¦¬\n",
    "\n",
    "### 6.1 ë²¡í„°í™” ë°©ë²• ìš”ì•½\n",
    "\n",
    "| ë°©ë²• | ë²¡í„°í™” í•¨ìˆ˜ | ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜ | íŠ¹ì§• |\n",
    "|------|------------|----------------|------|\n",
    "| BOW | `CountVectorizer().fit_transform()` | `cosine_similarity()` | ë‹¨ì–´ ë¹ˆë„ ê¸°ë°˜ |\n",
    "| TF-IDF | `TfidfVectorizer().fit_transform()` | `cosine_similarity()` | ë‹¨ì–´ ì¤‘ìš”ë„ ê¸°ë°˜ |\n",
    "| ì„ë² ë”© | `SentenceTransformer().encode()` | `cosine_similarity()` ë˜ëŠ” `model.similarity()` | ì˜ë¯¸ ê¸°ë°˜ |\n",
    "\n",
    "### 6.2 ì–¸ì œ ì–´ë–¤ ë°©ë²•ì„ ì‚¬ìš©í• ê¹Œ?\n",
    "\n",
    "| ìƒí™© | ì¶”ì²œ ë°©ë²• | ì´ìœ  |\n",
    "|------|----------|------|\n",
    "| ë¹ ë¥¸ í‚¤ì›Œë“œ ì¶”ì¶œ | BOW/TF-IDF | ë¹ ë¥¸ ì²˜ë¦¬, í•´ì„ ìš©ì´ |\n",
    "| ë¬¸ì„œ ë¶„ë¥˜ (ë‹¨ì–´ ë§¤ì¹­ ì¤‘ìš”) | TF-IDF | ì „í†µì  ML ëª¨ë¸ê³¼ í˜¸í™˜ |\n",
    "| ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ | ì„ë² ë”© | ë¬¸ë§¥ ì´í•´, ìœ ì‚¬ ì˜ë¯¸ ì¸ì‹ |\n",
    "| ê°ì„± ë¶„ì„ | ì„ë² ë”© | ë¬¸ë§¥ ê¸°ë°˜ ê°ì„± íŒŒì•… |\n",
    "| ëŒ€ëŸ‰ ë¬¸ì„œ ì²˜ë¦¬ (ì†ë„ ì¤‘ìš”) | TF-IDF | ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„ |\n",
    "| ì •í™•í•œ ì˜ë¯¸ ë¶„ì„ (ì •í™•ë„ ì¤‘ìš”) | ì„ë² ë”© | ë†’ì€ ì •í™•ë„ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01de2d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"[í•™ìŠµ ì •ë¦¬]\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "summary = \"\"\"\n",
    "1. BOW (Bag of Words)\n",
    "   - CountVectorizer ì‚¬ìš©\n",
    "   - ë‹¨ì–´ ë¹ˆë„ ê¸°ë°˜ í¬ì†Œ ë²¡í„°\n",
    "   - ë¹ ë¥´ì§€ë§Œ ì˜ë¯¸ ì´í•´ ì œí•œì \n",
    "\n",
    "2. TF-IDF\n",
    "   - TfidfVectorizer ì‚¬ìš©\n",
    "   - ë‹¨ì–´ ì¤‘ìš”ë„ ê¸°ë°˜ í¬ì†Œ ë²¡í„°\n",
    "   - cosine_similarity()ë¡œ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "   - ë‹¨ì–´ ë§¤ì¹­ ì¤‘ì‹¬ (ë‹¨ì–´ê°€ ë‹¤ë¥´ë©´ ìœ ì‚¬ë„ ë‚®ìŒ)\n",
    "\n",
    "3. ì„ë² ë”© (Sentence Transformer)\n",
    "   - SentenceTransformer.encode() ì‚¬ìš©\n",
    "   - ì˜ë¯¸ ê¸°ë°˜ ë°€ì§‘ ë²¡í„°\n",
    "   - cosine_similarity() ë˜ëŠ” model.similarity()ë¡œ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "   - ì˜ë¯¸ ìœ ì‚¬ë„ ì¤‘ì‹¬ (ì˜ë¯¸ê°€ ê°™ìœ¼ë©´ ìœ ì‚¬ë„ ë†’ìŒ)\n",
    "\n",
    "4. ì‹¤ë¬´ ì ìš©\n",
    "   - ìƒí™©ì— ë”°ë¼ ì ì ˆí•œ ë°©ë²• ì„ íƒ\n",
    "   - TF-IDF: ë¹ ë¥¸ ì²˜ë¦¬, í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "   - ì„ë² ë”©: ì •í™•í•œ ì˜ë¯¸ ë¶„ì„, ê°ì„± ë¶„ì„\n",
    "\"\"\"\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8de2b5a",
   "metadata": {},
   "source": [
    "---\n",
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "- 25ì°¨ì‹œ: ìì—°ì–´ ì²˜ë¦¬ ê¸°ì´ˆ ì‹¬í™”\n",
    "- 26ì°¨ì‹œ: ê¸ˆìœµ ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ì‹¤ìŠµ\n",
    "- 300ì°¨ì‹œ: Hugging Face íŒŒì´í”„ë¼ì¸ í™œìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4bb7d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
