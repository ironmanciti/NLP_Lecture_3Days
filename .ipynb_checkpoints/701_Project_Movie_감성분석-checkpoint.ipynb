{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61c0f4ab",
   "metadata": {},
   "source": [
    "# 프로젝트 B: 딥러닝 기반 영화 리뷰 분석 시스템\n",
    "\n",
    "## 프로젝트 목표\n",
    "- 딥러닝 기법(임베딩, BERT, RAG)을 활용한 영화 리뷰 분석 시스템 구축\n",
    "- 의미 기반 유사도 분석 및 감성 분석\n",
    "- RAG 기반 질의응답 시스템 구축\n",
    "- LLM을 활용한 요약 생성\n",
    "\n",
    "## 학습 내용\n",
    "1. 최소한의 데이터 전처리 (딥러닝 모델용)\n",
    "2. Sentence Transformer 임베딩\n",
    "3. Hugging Face 감성 분석\n",
    "4. RAG 기반 Q&A 시스템\n",
    "5. 요약 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea569a2",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. 데이터 준비 및 최소 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a48766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# Gemini API 클라이언트 초기화\n",
    "try:\n",
    "    client = genai.Client()\n",
    "    GEMINI_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Gemini API 초기화 실패: {e}\")\n",
    "    print(\"   .env 파일에 GOOGLE_API_KEY가 설정되어 있는지 확인하세요.\")\n",
    "    GEMINI_AVAILABLE = False\n",
    "\n",
    "# 네이버 영화평 데이터 다운로드\n",
    "DATA_TRAIN_PATH = tf.keras.utils.get_file(\n",
    "    \"ratings_train.txt\",\n",
    "    \"https://raw.github.com/ironmanciti/Infran_NLP/master/data/naver_movie/ratings_train.txt\"\n",
    ")\n",
    "DATA_TEST_PATH = tf.keras.utils.get_file(\n",
    "    \"ratings_test.txt\",\n",
    "    \"https://raw.github.com/ironmanciti/Infran_NLP/master/data/naver_movie/ratings_test.txt\"\n",
    ")\n",
    "\n",
    "# 데이터 로드\n",
    "train_data = pd.read_csv(DATA_TRAIN_PATH, delimiter='\\t')\n",
    "test_data = pd.read_csv(DATA_TEST_PATH, delimiter='\\t')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"[데이터 로드 완료]\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"훈련 데이터: {train_data.shape}\")\n",
    "print(f\"테스트 데이터: {test_data.shape}\")\n",
    "\n",
    "# 결측값 제거\n",
    "train_data.dropna(inplace=True)\n",
    "test_data.dropna(inplace=True)\n",
    "\n",
    "# 데이터 샘플링\n",
    "df_train = train_data.sample(n=5_000, random_state=1)\n",
    "df_test = test_data.sample(n=1_000, random_state=1)\n",
    "\n",
    "print(f\"\\n샘플링 후:\")\n",
    "print(f\"훈련 데이터: {df_train.shape}\")\n",
    "print(f\"테스트 데이터: {df_test.shape}\")\n",
    "\n",
    "# 딥러닝 모델용 최소 전처리 (결측값 제거만)\n",
    "df_train['cleaned_document'] = df_train['document'].astype(str)\n",
    "df_test['cleaned_document'] = df_test['document'].astype(str)\n",
    "\n",
    "# 빈 문자열 제거\n",
    "df_train = df_train[df_train['cleaned_document'].str.len() > 0]\n",
    "df_test = df_test[df_test['cleaned_document'].str.len() > 0]\n",
    "\n",
    "print(f\"\\n전처리 후:\")\n",
    "print(f\"훈련 데이터: {df_train.shape}\")\n",
    "print(f\"테스트 데이터: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c26964",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Sentence Transformer 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1950ac6e",
   "metadata": {},
   "source": [
    "### 2.1 임베딩 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6218f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"[Sentence Transformer 임베딩 생성]\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# KURE-v1 모델 로드 (한국어 특화)\n",
    "print(\"\\n임베딩 모델 로드 중...\")\n",
    "embedding_model = SentenceTransformer(\"nlpai-lab/KURE-v1\")\n",
    "print(\"✓ KURE-v1 모델 로드 완료\")\n",
    "\n",
    "# 샘플 데이터로 임베딩 생성 (전체 데이터는 시간이 오래 걸리므로 샘플 사용)\n",
    "sample_reviews = df_train['cleaned_document'].head(100).tolist()\n",
    "sample_labels = df_train['label'].head(100).tolist()\n",
    "\n",
    "print(f\"\\n임베딩 생성 중... (샘플 {len(sample_reviews)}개)\")\n",
    "embeddings = embedding_model.encode(sample_reviews)\n",
    "\n",
    "print(f\"임베딩 차원: {embeddings.shape}\")\n",
    "print(f\"  - 리뷰 수: {embeddings.shape[0]}\")\n",
    "print(f\"  - 벡터 차원: {embeddings.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079ef530",
   "metadata": {},
   "source": [
    "### 2.2 유사도 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddc538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"[임베딩 기반 유사도 분석]\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "# 유사한 리뷰 찾기 예시\n",
    "print(\"\\n[유사 리뷰 찾기 예시]\")\n",
    "query_idx = 0\n",
    "query_review = sample_reviews[query_idx]\n",
    "query_label = \"긍정\" if sample_labels[query_idx] == 1 else \"부정\"\n",
    "\n",
    "print(f\"\\n질의 리뷰: {query_review[:100]}...\")\n",
    "print(f\"레이블: {query_label}\")\n",
    "\n",
    "# 가장 유사한 리뷰 5개 찾기 (자기 자신 제외)\n",
    "similar_indices = np.argsort(similarity_matrix[query_idx])[-6:-1][::-1]\n",
    "\n",
    "print(\"\\n유사한 리뷰 Top 5:\")\n",
    "for i, idx in enumerate(similar_indices, 1):\n",
    "    similar_review = sample_reviews[idx]\n",
    "    similar_label = \"긍정\" if sample_labels[idx] == 1 else \"부정\"\n",
    "    similarity_score = similarity_matrix[query_idx][idx]\n",
    "    print(f\"\\n{i}. 유사도: {similarity_score:.4f}, 레이블: {similar_label}\")\n",
    "    print(f\"   리뷰: {similar_review[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2116b00d",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Hugging Face 감성 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f24311",
   "metadata": {},
   "source": [
    "### 3.1 파이프라인을 이용한 감성 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b7f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"[Hugging Face 감성 분석]\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 다국어 감성 분석 모델\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "sentiment_classifier = pipeline('sentiment-analysis', model=model_name)\n",
    "\n",
    "# 샘플 리뷰 분석\n",
    "sample_texts = [\n",
    "    \"다시는 보고 싶지 않은 짜증나는 영화\",\n",
    "    \"아주 재미있는 영화\",\n",
    "    \"정말 재미없는 영화였다\",\n",
    "    \"이 영화 최고\",\n",
    "    \"보통 영화\"\n",
    "]\n",
    "\n",
    "print(\"\\n[감성 분석 결과]\")\n",
    "results = sentiment_classifier(sample_texts)\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"{sample_texts[i]}\")\n",
    "    print(f\"  → {result['label']}, 신뢰도: {result['score']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8485b7bd",
   "metadata": {},
   "source": [
    "### 3.2 테스트 데이터 감성 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e58f91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"[테스트 데이터 감성 분석]\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 테스트 데이터 샘플 분석\n",
    "test_samples = df_test['cleaned_document'].head(10).tolist()\n",
    "test_labels = df_test['label'].head(10).tolist()\n",
    "\n",
    "print(\"\\n[테스트 데이터 샘플 분석]\")\n",
    "sentiment_results = sentiment_classifier(test_samples)\n",
    "\n",
    "correct = 0\n",
    "for i, (text, true_label, result) in enumerate(zip(test_samples, test_labels, sentiment_results)):\n",
    "    # 별점을 긍정/부정으로 변환 (4-5점: 긍정, 1-2점: 부정)\n",
    "    predicted_label = 1 if int(result['label'].split()[0]) >= 4 else 0\n",
    "    true_label_str = \"긍정\" if true_label == 1 else \"부정\"\n",
    "    predicted_label_str = \"긍정\" if predicted_label == 1 else \"부정\"\n",
    "    \n",
    "    is_correct = \"✓\" if true_label == predicted_label else \"✗\"\n",
    "    if true_label == predicted_label:\n",
    "        correct += 1\n",
    "    \n",
    "    print(f\"\\n리뷰 {i+1}: {text[:50]}...\")\n",
    "    print(f\"  실제: {true_label_str}, 예측: {predicted_label_str} ({result['label']}) {is_correct}\")\n",
    "\n",
    "accuracy = correct / len(test_samples)\n",
    "print(f\"\\n정확도: {accuracy:.4f} ({correct}/{len(test_samples)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc930d9",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. RAG 기반 Q&A 시스템"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6231ea",
   "metadata": {},
   "source": [
    "### 4.1 문서 임베딩 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67da21d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GEMINI_AVAILABLE:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"[RAG 기반 Q&A 시스템 구축]\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # RAG용 문서 준비 (긍정 리뷰와 부정 리뷰를 각각 샘플링)\n",
    "    positive_reviews = df_train[df_train['label'] == 1]['cleaned_document'].head(50).tolist()\n",
    "    negative_reviews = df_train[df_train['label'] == 0]['cleaned_document'].head(50).tolist()\n",
    "    \n",
    "    rag_documents = positive_reviews + negative_reviews\n",
    "    print(f\"\\nRAG 문서 수: {len(rag_documents)}개\")\n",
    "    \n",
    "    # 문서 임베딩 생성\n",
    "    print(\"\\n문서 임베딩 생성 중...\")\n",
    "    document_embeddings = embedding_model.encode(rag_documents)\n",
    "    print(f\"임베딩 완료: {document_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e3f82a",
   "metadata": {},
   "source": [
    "    # ### 4.2 유사 문서 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cd4f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def retrieve_similar_documents(query, documents, embeddings, top_k=3):\n",
    "        \"\"\"\n",
    "        질의와 유사한 문서 검색\n",
    "        \n",
    "        Args:\n",
    "            query: 질의 텍스트\n",
    "            documents: 문서 리스트\n",
    "            embeddings: 문서 임베딩 배열\n",
    "            top_k: 반환할 상위 문서 수\n",
    "            \n",
    "        Returns:\n",
    "            유사한 문서 리스트\n",
    "        \"\"\"\n",
    "        # 질의 임베딩 생성\n",
    "        query_embedding = embedding_model.encode([query])\n",
    "        \n",
    "        # 코사인 유사도 계산\n",
    "        similarities = cosine_similarity(query_embedding, embeddings)[0]\n",
    "        \n",
    "        # 상위 k개 문서 인덱스\n",
    "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "        \n",
    "        # 결과 반환\n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            results.append({\n",
    "                'document': documents[idx],\n",
    "                'similarity': similarities[idx]\n",
    "            })\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78355df",
   "metadata": {},
   "source": [
    "    # ### 4.3 RAG 질의응답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b321ccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def rag_qa(query, documents, embeddings, top_k=3):\n",
    "        \"\"\"\n",
    "        RAG 기반 질의응답\n",
    "        \n",
    "        Args:\n",
    "            query: 질의 텍스트\n",
    "            documents: 문서 리스트\n",
    "            embeddings: 문서 임베딩\n",
    "            top_k: 사용할 상위 문서 수\n",
    "            \n",
    "        Returns:\n",
    "            답변 텍스트\n",
    "        \"\"\"\n",
    "        # 유사 문서 검색\n",
    "        similar_docs = retrieve_similar_documents(query, documents, embeddings, top_k)\n",
    "        \n",
    "        # 컨텍스트 구성\n",
    "        context = \"\\n\\n\".join([f\"리뷰 {i+1}: {doc['document']}\" \n",
    "                               for i, doc in enumerate(similar_docs)])\n",
    "        \n",
    "        # 프롬프트 구성\n",
    "        prompt = f\"\"\"다음은 영화 리뷰들입니다. 질문에 답변해주세요.\n",
    "\n",
    "리뷰들:\n",
    "{context}\n",
    "\n",
    "질문: {query}\n",
    "\n",
    "답변:\"\"\"\n",
    "        \n",
    "        # Gemini API 호출\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.5-flash\",\n",
    "                contents=prompt\n",
    "            )\n",
    "            return response.text, similar_docs\n",
    "        except Exception as e:\n",
    "            return f\"오류 발생: {e}\", similar_docs\n",
    "    \n",
    "    # 질의응답 테스트\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"[RAG 질의응답 테스트]\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    test_queries = [\n",
    "        \"긍정적인 리뷰들의 공통점은 무엇인가요?\",\n",
    "        \"부정적인 리뷰에서 자주 언급되는 문제점은 무엇인가요?\",\n",
    "        \"이 영화의 장점은 무엇인가요?\"\n",
    "    ]\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"\\n질문: {query}\")\n",
    "        print(\"-\" * 80)\n",
    "        answer, similar_docs = rag_qa(query, rag_documents, document_embeddings, top_k=3)\n",
    "        print(f\"답변: {answer}\")\n",
    "        print(f\"\\n참고한 리뷰 수: {len(similar_docs)}개\")\n",
    "        for i, doc in enumerate(similar_docs[:2], 1):\n",
    "            print(f\"  {i}. (유사도: {doc['similarity']:.4f}) {doc['document'][:80]}...\")\n",
    "\n",
    "else:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"[RAG 기반 Q&A 시스템]\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"⚠️ Gemini API가 설정되지 않아 RAG 기능을 건너뜁니다.\")\n",
    "    print(\"   .env 파일에 GOOGLE_API_KEY를 설정하세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283b375f",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. 요약 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a4237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GEMINI_AVAILABLE:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"[요약 생성]\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    def summarize_reviews(reviews, max_reviews=10):\n",
    "        \"\"\"\n",
    "        리뷰 요약 생성\n",
    "        \n",
    "        Args:\n",
    "            reviews: 리뷰 리스트\n",
    "            max_reviews: 요약에 사용할 최대 리뷰 수\n",
    "            \n",
    "        Returns:\n",
    "            요약 텍스트\n",
    "        \"\"\"\n",
    "        # 샘플 리뷰 선택\n",
    "        sample_reviews = reviews[:max_reviews]\n",
    "        \n",
    "        # 리뷰 텍스트 결합\n",
    "        reviews_text = \"\\n\\n\".join([f\"리뷰 {i+1}: {review}\" \n",
    "                                   for i, review in enumerate(sample_reviews)])\n",
    "        \n",
    "        # 프롬프트 구성\n",
    "        prompt = f\"\"\"다음은 영화 리뷰들입니다. 이 리뷰들을 요약해주세요.\n",
    "\n",
    "리뷰들:\n",
    "{reviews_text}\n",
    "\n",
    "요약:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.5-flash\",\n",
    "                contents=prompt\n",
    "            )\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            return f\"오류 발생: {e}\"\n",
    "    \n",
    "    # 긍정 리뷰 요약\n",
    "    print(\"\\n[긍정 리뷰 요약]\")\n",
    "    positive_summary = summarize_reviews(positive_reviews[:10])\n",
    "    print(positive_summary)\n",
    "    \n",
    "    # 부정 리뷰 요약\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"[부정 리뷰 요약]\")\n",
    "    print(\"=\" * 80)\n",
    "    negative_summary = summarize_reviews(negative_reviews[:10])\n",
    "    print(negative_summary)\n",
    "\n",
    "else:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"[요약 생성]\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"⚠️ Gemini API가 설정되지 않아 요약 기능을 건너뜁니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bf53f2",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. 프로젝트 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e7e1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"[프로젝트 정리]\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "summary = \"\"\"\n",
    "프로젝트 B: 딥러닝 기반 영화 리뷰 분석 시스템\n",
    "\n",
    "1. 최소한의 데이터 전처리\n",
    "   - 결측값 제거만 수행\n",
    "   - 딥러닝 모델이 원본 패턴을 학습했으므로 과도한 전처리 불필요\n",
    "\n",
    "2. Sentence Transformer 임베딩\n",
    "   - 의미 기반 밀집 벡터 생성\n",
    "   - 유사한 의미의 리뷰는 유사한 벡터\n",
    "   - 유사도 분석 및 추천 시스템\n",
    "\n",
    "3. Hugging Face 감성 분석\n",
    "   - 사전 학습된 BERT 모델 활용\n",
    "   - 파이프라인을 통한 간편한 사용\n",
    "   - 높은 정확도\n",
    "\n",
    "4. RAG 기반 Q&A 시스템\n",
    "   - 문서 임베딩 생성\n",
    "   - 유사 문서 검색\n",
    "   - LLM을 활용한 답변 생성\n",
    "   - 컨텍스트 기반 정확한 답변\n",
    "\n",
    "5. 요약 생성\n",
    "   - LLM을 활용한 리뷰 요약\n",
    "   - 긍정/부정 리뷰 요약\n",
    "\n",
    "특징:\n",
    "- 높은 정확도\n",
    "- 의미 이해 기반\n",
    "- 고급 기능 (Q&A, 요약)\n",
    "- GPU 활용 가능\n",
    "\"\"\"\n",
    "\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
