# ---
# jupyter:
#   jupytext:
#     formats: ipynb,py:percent
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.17.3
#   kernelspec:
#     display_name: Python 3 (ipykernel)
#     language: python
#     name: python3
# ---

# %% [markdown]
# # ë¬¸ì¥ ë²¡í„°í™”: BOW, TF-IDF vs ì„ë² ë”©
#
# ## í•™ìŠµ ëª©í‘œ
# - BOW (Bag of Words) ë²¡í„°í™” ë°©ë²• ì´í•´
# - TF-IDF ë²¡í„°í™” ë°©ë²• ì´í•´
# - TF-IDF ë²¡í„° ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚° (cosine_similarity)
# - Sentence Transformer ì„ë² ë”© ë°©ë²• ì´í•´
# - ì„ë² ë”© ë²¡í„° ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
# - ë‘ ë°©ì‹ì˜ ì°¨ì´ì  ì´í•´ (ë‹¨ì–´ ë§¤ì¹­ vs ì˜ë¯¸ ìœ ì‚¬ë„)
#
# ## í•™ìŠµ ë‚´ìš©
# 1. BOW (Bag of Words) ë²¡í„°í™”
# 2. TF-IDF ë²¡í„°í™” ë° ìœ ì‚¬ë„ ê³„ì‚°
# 3. Sentence Transformer ì„ë² ë”© ë° ìœ ì‚¬ë„ ê³„ì‚°
# 4. ë°©ë²•ë¡  ë¹„êµ: ë‹¨ì–´ ë§¤ì¹­ vs ì˜ë¯¸ ìœ ì‚¬ë„

# %% [markdown]
# ---
# ## 1. ë°ì´í„° ì¤€ë¹„

# %%
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
import warnings
warnings.filterwarnings('ignore')

# ê¸ˆìœµ ë‰´ìŠ¤ ì˜ˆì‹œ ë°ì´í„°
finance_news = [
    "ì‚¼ì„±ì „ì 3ë¶„ê¸° ì˜ì—…ì´ìµ ê¸‰ë“±, ì‚¬ìƒìµœê³  ì‹¤ì  ê¸°ëŒ€",
    "ì½”ìŠ¤í”¼ í•˜ë½ì„¸ ì§€ì†, ì™¸êµ­ì¸ ìˆœë§¤ë„ í™•ëŒ€ì— ìš°ë ¤",
    "ë°˜ë„ì²´ ì‹œì¥ ì„±ì¥ì„¸ ì§€ì†, ë©”ëª¨ë¦¬ ë°˜ë„ì²´ ìˆ˜ìš” ì¦ê°€",
    "ì‚¼ì„±ì „ì ì£¼ê°€ ìƒìŠ¹, ì‹¤ì  í˜¸ì¡° ì „ë§ ë‚™ê´€",
    "ê¸ˆë¦¬ ì¸ìƒ ìš°ë ¤ë¡œ ì£¼ì‹ ì‹œì¥ í•˜ë½"
]

print("=" * 80)
print("ê¸ˆìœµ ë‰´ìŠ¤ ë°ì´í„°")
print("=" * 80)
for i, news in enumerate(finance_news, 1):
    print(f"{i}. {news}")

# %% [markdown]
# ---
# ## 2. BOW (Bag of Words) ë²¡í„°í™”
#
# **BOWì˜ íŠ¹ì§•:**
# - ë‹¨ì–´ì˜ ìˆœì„œë¥¼ ë¬´ì‹œí•˜ê³  ë‹¨ì–´ ë¹ˆë„ë§Œ ê³ ë ¤
# - í¬ì†Œ ë²¡í„°(Sparse Vector) ìƒì„±
# - ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„
# - ì˜ë¯¸ì  ìœ ì‚¬ë„ íŒŒì•… ì–´ë ¤ì›€

# %%
print("\n" + "=" * 80)
print("[BOW - Bag of Words ë²¡í„°í™”]")
print("=" * 80)

# CountVectorizer ê°ì²´ ìƒì„±
count_vectorizer = CountVectorizer()

# ë¬¸ì¥ë“¤ì„ ë²¡í„°ë¡œ ë³€í™˜
bow_features = count_vectorizer.fit_transform(finance_news)
bow_array = bow_features.toarray()

# ë‹¨ì–´ ëª©ë¡
feature_names = count_vectorizer.get_feature_names_out()

print(f"\në¬¸ì„œ ìˆ˜: {bow_features.shape[0]}")
print(f"ë‹¨ì–´ ìˆ˜: {bow_features.shape[1]}")
print(f"\në‹¨ì–´ ëª©ë¡ (ì¼ë¶€): {list(feature_names[:15])}...")

# DataFrameìœ¼ë¡œ ì‹œê°í™”
df_bow = pd.DataFrame(
    bow_array, 
    columns=feature_names, 
    index=[f"ë‰´ìŠ¤{i+1}" for i in range(len(finance_news))]
)
print("\n[BOW ë²¡í„° í–‰ë ¬]")
print(df_bow)

# %% [markdown]
# ---
# ## 3. TF-IDF ë²¡í„°í™” ë° ìœ ì‚¬ë„ ê³„ì‚°
#
# **TF-IDFì˜ íŠ¹ì§•:**
# - ë‹¨ì–´ì˜ ì¤‘ìš”ë„ë¥¼ ë¬¸ì„œ ë‚´ ë¹ˆë„ì™€ ì „ì²´ ë¬¸ì„œì—ì„œì˜ í¬ê·€ë„ë¥¼ ê³ ë ¤
# - BOWë³´ë‹¤ ì˜ë¯¸ ìˆëŠ” ê°€ì¤‘ì¹˜ ë¶€ì—¬
# - ì—¬ì „íˆ í¬ì†Œ ë²¡í„°ì´ì§€ë§Œ BOWë³´ë‹¤ ì •ë³´ëŸ‰ì´ ë§ìŒ

# %%
print("\n" + "=" * 80)
print("[TF-IDF ë²¡í„°í™”]")
print("=" * 80)

# TfidfVectorizer ê°ì²´ ìƒì„±
tfidf_vectorizer = TfidfVectorizer()

# ë¬¸ì¥ë“¤ì„ TF-IDF ë²¡í„°ë¡œ ë³€í™˜
tfidf_features = tfidf_vectorizer.fit_transform(finance_news)
tfidf_array = tfidf_features.toarray()

# ë‹¨ì–´ ëª©ë¡
tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()

print(f"\në¬¸ì„œ ìˆ˜: {tfidf_features.shape[0]}")
print(f"ë‹¨ì–´ ìˆ˜: {tfidf_features.shape[1]}")

# DataFrameìœ¼ë¡œ ì‹œê°í™”
df_tfidf = pd.DataFrame(
    tfidf_array, 
    columns=tfidf_feature_names, 
    index=[f"ë‰´ìŠ¤{i+1}" for i in range(len(finance_news))]
)
print("\n[TF-IDF ë²¡í„° í–‰ë ¬]")
print(df_tfidf.round(3))

# %% [markdown]
# ### 3.1 TF-IDF ë²¡í„° ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚° (cosine_similarity)

# %%
print("\n" + "=" * 80)
print("[TF-IDF ë²¡í„° ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚° - cosine_similarity]")
print("=" * 80)

# TF-IDF ë²¡í„° ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
tfidf_similarity = cosine_similarity(tfidf_features)

# ìœ ì‚¬ë„ í–‰ë ¬ì„ DataFrameìœ¼ë¡œ ë³€í™˜
df_tfidf_sim = pd.DataFrame(
    tfidf_similarity,
    index=[f"ë‰´ìŠ¤{i+1}" for i in range(len(finance_news))],
    columns=[f"ë‰´ìŠ¤{i+1}" for i in range(len(finance_news))]
)
print("\n[TF-IDF ê¸°ë°˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ í–‰ë ¬]")
print(df_tfidf_sim.round(3))

# ë‰´ìŠ¤ ìŒë³„ ìœ ì‚¬ë„ ì¶œë ¥
print("\n[ë‰´ìŠ¤ ìŒë³„ ìœ ì‚¬ë„]")
for i in range(len(finance_news)):
    for j in range(i+1, len(finance_news)):
        sim = tfidf_similarity[i][j]
        print(f"  ë‰´ìŠ¤{i+1} vs ë‰´ìŠ¤{j+1}: {sim:.4f}")
        print(f"    '{finance_news[i]}'")
        print(f"    '{finance_news[j]}'")
        print()

# %% [markdown]
# ---
# ## 4. Sentence Transformer ì„ë² ë”© ë° ìœ ì‚¬ë„ ê³„ì‚°
#
# **ì„ë² ë”©ì˜ íŠ¹ì§•:**
# - ë¬¸ì¥ ì „ì²´ë¥¼ ê³ ì • í¬ê¸°ì˜ ë°€ì§‘ ë²¡í„°(Dense Vector)ë¡œ ë³€í™˜
# - ë¬¸ë§¥ê³¼ ì˜ë¯¸ë¥¼ ì´í•´í•˜ì—¬ ìœ ì‚¬í•œ ì˜ë¯¸ì˜ ë¬¸ì¥ì€ ìœ ì‚¬í•œ ë²¡í„° ìƒì„±
# - ë‹¨ì–´ ìˆœì„œì™€ ë¬¸ë§¥ì„ ê³ ë ¤
# - ê³„ì‚° ë¹„ìš©ì´ ë†’ì§€ë§Œ ì •í™•ë„ê°€ ë†’ìŒ

# %%
print("\n" + "=" * 80)
print("[Sentence Transformer ì„ë² ë”©]")
print("=" * 80)

# KURE-v1 ëª¨ë¸ ë¡œë“œ (í•œêµ­ì–´ íŠ¹í™”)
print("\nì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘...")
model = SentenceTransformer("nlpai-lab/KURE-v1")
print("âœ“ KURE-v1 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (í•œêµ­ì–´ íŠ¹í™” ë¬¸ì¥ ì„ë² ë”© ëª¨ë¸)")

# ë¬¸ì¥ë“¤ì„ ë²¡í„°ë¡œ ë³€í™˜
embeddings = model.encode(finance_news)

print(f"\nì„ë² ë”© ì°¨ì›: {embeddings.shape}")
print(f"  - ë¬¸ì¥ ìˆ˜: {embeddings.shape[0]}")
print(f"  - ë²¡í„° ì°¨ì›: {embeddings.shape[1]}")

# ì²« ë²ˆì§¸ ë¬¸ì¥ì˜ ì„ë² ë”© ë²¡í„° ì¼ë¶€ í™•ì¸
print(f"\nì²« ë²ˆì§¸ ë‰´ìŠ¤ ì„ë² ë”© ë²¡í„° (ì²˜ìŒ 10ê°œ ê°’):")
print(embeddings[0][:10])

# %% [markdown]
# ### 4.1 ì„ë² ë”© ë²¡í„° ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°

# %%
print("\n" + "=" * 80)
print("[ì„ë² ë”© ë²¡í„° ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°]")
print("=" * 80)

# ë°©ë²• 1: model.similarity() ì‚¬ìš©
embedding_similarity_model = model.similarity(embeddings, embeddings)

# ë°©ë²• 2: cosine_similarity() ì§ì ‘ ì‚¬ìš© (ë™ì¼í•œ ê²°ê³¼)
embedding_similarity_cosine = cosine_similarity(embeddings)

print("\n[ë°©ë²• 1: model.similarity() ì‚¬ìš©]")
df_embed_sim_model = pd.DataFrame(
    embedding_similarity_model.numpy(),
    index=[f"ë‰´ìŠ¤{i+1}" for i in range(len(finance_news))],
    columns=[f"ë‰´ìŠ¤{i+1}" for i in range(len(finance_news))]
)
print(df_embed_sim_model.round(3))

print("\n[ë°©ë²• 2: cosine_similarity() ì§ì ‘ ì‚¬ìš©]")
df_embed_sim_cosine = pd.DataFrame(
    embedding_similarity_cosine,
    index=[f"ë‰´ìŠ¤{i+1}" for i in range(len(finance_news))],
    columns=[f"ë‰´ìŠ¤{i+1}" for i in range(len(finance_news))]
)
print(df_embed_sim_cosine.round(3))

print("\nğŸ’¡ ë‘ ë°©ë²• ëª¨ë‘ ë™ì¼í•œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤!")

# ë‰´ìŠ¤ ìŒë³„ ìœ ì‚¬ë„ ì¶œë ¥
print("\n[ë‰´ìŠ¤ ìŒë³„ ìœ ì‚¬ë„]")
for i in range(len(finance_news)):
    for j in range(i+1, len(finance_news)):
        sim = embedding_similarity_cosine[i][j]
        print(f"  ë‰´ìŠ¤{i+1} vs ë‰´ìŠ¤{j+1}: {sim:.4f}")
        print(f"    '{finance_news[i]}'")
        print(f"    '{finance_news[j]}'")
        print()

# %% [markdown]
# ---
# ## 5. ë°©ë²•ë¡  ë¹„êµ: ë‹¨ì–´ ë§¤ì¹­ vs ì˜ë¯¸ ìœ ì‚¬ë„
#
# ### 5.1 TF-IDFì™€ ì„ë² ë”©ì˜ ì°¨ì´ì  ë¹„êµ

# %%
print("=" * 80)
print("[TF-IDF vs ì„ë² ë”©: ë‹¨ì–´ ë§¤ì¹­ vs ì˜ë¯¸ ìœ ì‚¬ë„ ë¹„êµ]")
print("=" * 80)

# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: ì˜ë¯¸ëŠ” ê°™ì§€ë§Œ ë‹¨ì–´ê°€ ë‹¤ë¥¸ ë¬¸ì¥ë“¤
test_cases = [
    {
        'name': 'ì˜ë¯¸ ë™ì¼, ë‹¨ì–´ ë‹¤ë¦„',
        'text1': 'ì‚¼ì„±ì „ì ì£¼ê°€ê°€ ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤',
        'text2': 'ì‚¼ì„±ì „ì ì£¼ì‹ ê°€ê²©ì´ ì˜¬ëìŠµë‹ˆë‹¤'  # ì˜ë¯¸ëŠ” ê°™ì§€ë§Œ ë‹¨ì–´ê°€ ë‹¤ë¦„
    },
    {
        'name': 'ì˜ë¯¸ ìœ ì‚¬, í‘œí˜„ ë‹¤ë¦„',
        'text1': 'ì£¼ê°€ ìƒìŠ¹ ì‹¤ì  í˜¸ì¡° ì „ë§ ë‚™ê´€',
        'text2': 'ì£¼ì‹ ê°€ê²© ì¦ê°€ ì‹¤ì  ì¢‹ìŒ ì „ë§ ê¸ì •ì '  # ì˜ë¯¸ ìœ ì‚¬í•˜ì§€ë§Œ í‘œí˜„ ë‹¤ë¦„
    },
    {
        'name': 'ì˜ë¯¸ ë‹¤ë¦„',
        'text1': 'ì‚¼ì„±ì „ì ì£¼ê°€ ìƒìŠ¹',
        'text2': 'ì½”ìŠ¤í”¼ ì§€ìˆ˜ í•˜ë½'  # ì™„ì „íˆ ë‹¤ë¥¸ ì˜ë¯¸
    },
    {
        'name': 'ë‹¨ì–´ ì¼ë¶€ ê²¹ì¹¨',
        'text1': 'ë°˜ë„ì²´ ì‹œì¥ ì„±ì¥',
        'text2': 'ë°˜ë„ì²´ ìˆ˜ìš” ì¦ê°€'  # ì¼ë¶€ ë‹¨ì–´ ê²¹ì¹¨
    }
]

# ê²°ê³¼ ì €ì¥
results = []

for case in test_cases:
    text1 = case['text1']
    text2 = case['text2']
    
    # === TF-IDF ë°©ì‹ ===
    tfidf_test = TfidfVectorizer()
    tfidf_vectors = tfidf_test.fit_transform([text1, text2])
    tfidf_sim = cosine_similarity(tfidf_vectors[0:1], tfidf_vectors[1:2])[0][0]
    
    # ê³µí†µ ë‹¨ì–´ í™•ì¸
    words1 = set(text1.split())
    words2 = set(text2.split())
    common_words = words1.intersection(words2)
    
    # === ì„ë² ë”© ë°©ì‹ ===
    emb_vectors = model.encode([text1, text2])
    emb_sim = cosine_similarity([emb_vectors[0]], [emb_vectors[1]])[0][0]
    
    results.append({
        'ì¼€ì´ìŠ¤': case['name'],
        'ë¬¸ì¥1': text1,
        'ë¬¸ì¥2': text2,
        'ê³µí†µë‹¨ì–´': ', '.join(common_words) if common_words else 'ì—†ìŒ',
        'TF-IDF_ìœ ì‚¬ë„': tfidf_sim,
        'ì„ë² ë”©_ìœ ì‚¬ë„': emb_sim,
        'ì°¨ì´': emb_sim - tfidf_sim
    })
    
    # ìƒì„¸ ì¶œë ¥
    print("-" * 80)
    print(f"[ì¼€ì´ìŠ¤: {case['name']}]")
    print(f"  ë¬¸ì¥1: {text1}")
    print(f"  ë¬¸ì¥2: {text2}")
    print(f"  ê³µí†µ ë‹¨ì–´: {', '.join(common_words) if common_words else 'ì—†ìŒ'}")
    print(f"\n  TF-IDF ìœ ì‚¬ë„: {tfidf_sim:.4f} {'(ë‹¨ì–´ ë§¤ì¹­ ì¤‘ì‹¬)' if tfidf_sim < 0.3 else '(ë‹¨ì–´ ê²¹ì¹¨)'}")
    print(f"  ì„ë² ë”© ìœ ì‚¬ë„: {emb_sim:.4f} {'(ì˜ë¯¸ ìœ ì‚¬ë„ ì¤‘ì‹¬)' if emb_sim > 0.5 else '(ì˜ë¯¸ ë‹¤ë¦„)'}")
    print(f"  ì°¨ì´: {emb_sim - tfidf_sim:+.4f}")
    
    # í•´ì„
    if tfidf_sim < 0.3 and emb_sim > 0.5:
        print(f"\n  ğŸ’¡ í•´ì„: ë‹¨ì–´ê°€ ë‹¤ë¥´ì§€ë§Œ ì˜ë¯¸ê°€ ìœ ì‚¬ â†’ TF-IDFëŠ” ë‚®ê²Œ, ì„ë² ë”©ì€ ë†’ê²Œ í‰ê°€")
    elif tfidf_sim > 0.3 and emb_sim < 0.5:
        print(f"\n  ğŸ’¡ í•´ì„: ë‹¨ì–´ëŠ” ê²¹ì¹˜ì§€ë§Œ ì˜ë¯¸ê°€ ë‹¤ë¦„ â†’ TF-IDFëŠ” ë†’ê²Œ, ì„ë² ë”©ì€ ë‚®ê²Œ í‰ê°€")
    print()

# ê²°ê³¼ ìš”ì•½ í…Œì´ë¸”
print("=" * 80)
print("[ê²°ê³¼ ìš”ì•½]")
print("=" * 80)

df_results = pd.DataFrame(results)
print("\n[ìƒì„¸ ê²°ê³¼]")
print(df_results[['ì¼€ì´ìŠ¤', 'TF-IDF_ìœ ì‚¬ë„', 'ì„ë² ë”©_ìœ ì‚¬ë„', 'ì°¨ì´']].to_string(index=False))

# %% [markdown]
# ### 5.2 í•µì‹¬ ì°¨ì´ì  ìš”ì•½

# %%
print("\n" + "=" * 80)
print("[í•µì‹¬ ì°¨ì´ì  ìš”ì•½]")
print("=" * 80)

comparison_data = {
    'íŠ¹ì„±': [
        'ë²¡í„° íƒ€ì…',
        'ë²¡í„° ì°¨ì›',
        'ìœ ì‚¬ë„ ê¸°ì¤€',
        'ë‹¨ì–´ ìˆœì„œ ê³ ë ¤',
        'ê³„ì‚° ì†ë„',
        'ì˜ë¯¸ ì´í•´',
        'ì£¼ìš” í™œìš© ë¶„ì•¼'
    ],
    'TF-IDF': [
        'í¬ì†Œ ë²¡í„° (Sparse)',
        'ì–´íœ˜ í¬ê¸°ì— ë”°ë¼ ê°€ë³€',
        'ë‹¨ì–´ ë§¤ì¹­ ì¤‘ì‹¬',
        'âŒ ë¬´ì‹œ',
        'âš¡ ë§¤ìš° ë¹ ë¦„',
        'ì œí•œì  (ë¹ˆë„ ê¸°ë°˜)',
        'í‚¤ì›Œë“œ ì¶”ì¶œ, ë¬¸ì„œ ë¶„ë¥˜'
    ],
    'ì„ë² ë”©': [
        'ë°€ì§‘ ë²¡í„° (Dense)',
        'ê³ ì • (1024ì°¨ì›)',
        'ì˜ë¯¸ ìœ ì‚¬ë„ ì¤‘ì‹¬',
        'âœ… ê³ ë ¤',
        'ğŸŒ ëŠë¦¼',
        'ìš°ìˆ˜ (ë¬¸ë§¥ ê¸°ë°˜)',
        'ìœ ì‚¬ë„ ê²€ìƒ‰, ê°ì„± ë¶„ì„'
    ]
}

df_comparison = pd.DataFrame(comparison_data)
print("\n")
print(df_comparison.to_string(index=False))

print("""
\n[í•µì‹¬ ì •ë¦¬]

1. TF-IDF (ë‹¨ì–´ ë§¤ì¹­ ì¤‘ì‹¬)
   âœ“ ë‹¨ì–´ê°€ ê²¹ì¹˜ë©´ ìœ ì‚¬ë„ ë†’ìŒ
   âœ— ë‹¨ì–´ê°€ ë‹¤ë¥´ë©´ ìœ ì‚¬ë„ ë‚®ìŒ (ì˜ë¯¸ê°€ ê°™ì•„ë„)
   â†’ "ì£¼ê°€ ìƒìŠ¹" vs "ì£¼ì‹ ê°€ê²© ì¦ê°€" â†’ ë‚®ì€ ìœ ì‚¬ë„

2. ì„ë² ë”© (ì˜ë¯¸ ìœ ì‚¬ë„ ì¤‘ì‹¬)
   âœ“ ì˜ë¯¸ê°€ ê°™ìœ¼ë©´ ìœ ì‚¬ë„ ë†’ìŒ (ë‹¨ì–´ê°€ ë‹¬ë¼ë„)
   âœ— ì˜ë¯¸ê°€ ë‹¤ë¥´ë©´ ìœ ì‚¬ë„ ë‚®ìŒ (ë‹¨ì–´ê°€ ê²¹ì³ë„)
   â†’ "ì£¼ê°€ ìƒìŠ¹" vs "ì£¼ì‹ ê°€ê²© ì¦ê°€" â†’ ë†’ì€ ìœ ì‚¬ë„
""")

# %% [markdown]
# ---
# ## 6. í•™ìŠµ ì •ë¦¬
#
# ### 6.1 ë²¡í„°í™” ë°©ë²• ìš”ì•½
#
# | ë°©ë²• | ë²¡í„°í™” í•¨ìˆ˜ | ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜ | íŠ¹ì§• |
# |------|------------|----------------|------|
# | BOW | `CountVectorizer().fit_transform()` | `cosine_similarity()` | ë‹¨ì–´ ë¹ˆë„ ê¸°ë°˜ |
# | TF-IDF | `TfidfVectorizer().fit_transform()` | `cosine_similarity()` | ë‹¨ì–´ ì¤‘ìš”ë„ ê¸°ë°˜ |
# | ì„ë² ë”© | `SentenceTransformer().encode()` | `cosine_similarity()` ë˜ëŠ” `model.similarity()` | ì˜ë¯¸ ê¸°ë°˜ |
#
# ### 6.2 ì–¸ì œ ì–´ë–¤ ë°©ë²•ì„ ì‚¬ìš©í• ê¹Œ?
#
# | ìƒí™© | ì¶”ì²œ ë°©ë²• | ì´ìœ  |
# |------|----------|------|
# | ë¹ ë¥¸ í‚¤ì›Œë“œ ì¶”ì¶œ | BOW/TF-IDF | ë¹ ë¥¸ ì²˜ë¦¬, í•´ì„ ìš©ì´ |
# | ë¬¸ì„œ ë¶„ë¥˜ (ë‹¨ì–´ ë§¤ì¹­ ì¤‘ìš”) | TF-IDF | ì „í†µì  ML ëª¨ë¸ê³¼ í˜¸í™˜ |
# | ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ | ì„ë² ë”© | ë¬¸ë§¥ ì´í•´, ìœ ì‚¬ ì˜ë¯¸ ì¸ì‹ |
# | ê°ì„± ë¶„ì„ | ì„ë² ë”© | ë¬¸ë§¥ ê¸°ë°˜ ê°ì„± íŒŒì•… |
# | ëŒ€ëŸ‰ ë¬¸ì„œ ì²˜ë¦¬ (ì†ë„ ì¤‘ìš”) | TF-IDF | ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„ |
# | ì •í™•í•œ ì˜ë¯¸ ë¶„ì„ (ì •í™•ë„ ì¤‘ìš”) | ì„ë² ë”© | ë†’ì€ ì •í™•ë„ |

# %%
print("=" * 80)
print("[í•™ìŠµ ì •ë¦¬]")
print("=" * 80)

summary = """
1. BOW (Bag of Words)
   - CountVectorizer ì‚¬ìš©
   - ë‹¨ì–´ ë¹ˆë„ ê¸°ë°˜ í¬ì†Œ ë²¡í„°
   - ë¹ ë¥´ì§€ë§Œ ì˜ë¯¸ ì´í•´ ì œí•œì 

2. TF-IDF
   - TfidfVectorizer ì‚¬ìš©
   - ë‹¨ì–´ ì¤‘ìš”ë„ ê¸°ë°˜ í¬ì†Œ ë²¡í„°
   - cosine_similarity()ë¡œ ìœ ì‚¬ë„ ê³„ì‚°
   - ë‹¨ì–´ ë§¤ì¹­ ì¤‘ì‹¬ (ë‹¨ì–´ê°€ ë‹¤ë¥´ë©´ ìœ ì‚¬ë„ ë‚®ìŒ)

3. ì„ë² ë”© (Sentence Transformer)
   - SentenceTransformer.encode() ì‚¬ìš©
   - ì˜ë¯¸ ê¸°ë°˜ ë°€ì§‘ ë²¡í„°
   - cosine_similarity() ë˜ëŠ” model.similarity()ë¡œ ìœ ì‚¬ë„ ê³„ì‚°
   - ì˜ë¯¸ ìœ ì‚¬ë„ ì¤‘ì‹¬ (ì˜ë¯¸ê°€ ê°™ìœ¼ë©´ ìœ ì‚¬ë„ ë†’ìŒ)

4. ì‹¤ë¬´ ì ìš©
   - ìƒí™©ì— ë”°ë¼ ì ì ˆí•œ ë°©ë²• ì„ íƒ
   - TF-IDF: ë¹ ë¥¸ ì²˜ë¦¬, í‚¤ì›Œë“œ ì¶”ì¶œ
   - ì„ë² ë”©: ì •í™•í•œ ì˜ë¯¸ ë¶„ì„, ê°ì„± ë¶„ì„
"""

print(summary)

# %% [markdown]
# ---
# ### ë‹¤ìŒ ë‹¨ê³„
# - 25ì°¨ì‹œ: ìì—°ì–´ ì²˜ë¦¬ ê¸°ì´ˆ ì‹¬í™”
# - 26ì°¨ì‹œ: ê¸ˆìœµ ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ì‹¤ìŠµ
# - 300ì°¨ì‹œ: Hugging Face íŒŒì´í”„ë¼ì¸ í™œìš©

# %%

