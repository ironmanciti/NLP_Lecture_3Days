{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a001ecab",
   "metadata": {
    "id": "a001ecab"
   },
   "source": [
    "# 문장 벡터화: BOW, TF-IDF vs 임베딩\n",
    "\n",
    "## 학습 목표\n",
    "- BOW (Bag of Words) 벡터화 방법 이해\n",
    "- TF-IDF 벡터화 방법 이해\n",
    "- TF-IDF 벡터 기반 유사도 계산 (cosine_similarity)\n",
    "- Sentence Transformer 임베딩 방법 이해\n",
    "- 임베딩 벡터 기반 유사도 계산\n",
    "- 두 방식의 차이점 이해 (단어 매칭 vs 의미 유사도)\n",
    "\n",
    "## 학습 내용\n",
    "1. BOW (Bag of Words) 벡터화\n",
    "2. TF-IDF 벡터화 및 유사도 계산\n",
    "3. Sentence Transformer 임베딩 및 유사도 계산\n",
    "4. 방법론 비교: 단어 매칭 vs 의미 유사도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4429fbb",
   "metadata": {
    "id": "d4429fbb"
   },
   "source": [
    "---\n",
    "## 1. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 금융 뉴스 예시 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79f4705",
   "metadata": {
    "id": "f79f4705"
   },
   "source": [
    "---\n",
    "## 2. BOW (Bag of Words) 벡터화\n",
    "\n",
    "**BOW의 특징:**\n",
    "- 단어의 순서를 무시하고 단어 빈도만 고려\n",
    "- 희소 벡터(Sparse Vector) 생성\n",
    "- 빠른 처리 속도\n",
    "- 의미적 유사도 파악 어려움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f96c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer 객체 생성\n",
    "# 문장들을 벡터로 변환\n",
    "# 단어 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230fe8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame으로 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f342a0",
   "metadata": {
    "id": "84f342a0"
   },
   "source": [
    "---\n",
    "## 3. TF-IDF 벡터화 및 유사도 계산\n",
    "\n",
    "**TF-IDF의 특징:**\n",
    "- 단어의 중요도를 문서 내 빈도와 전체 문서에서의 희귀도를 고려\n",
    "- BOW보다 의미 있는 가중치 부여\n",
    "- 여전히 희소 벡터이지만 BOW보다 정보량이 많음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677caf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer 객체 생성\n",
    "# 문장들을 TF-IDF 벡터로 변환\n",
    "# 단어 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a647c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame으로 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca00faf",
   "metadata": {
    "id": "5ca00faf"
   },
   "source": [
    "### 3.1 TF-IDF 벡터 기반 유사도 계산 (cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db22f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 벡터 간 코사인 유사도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d47df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 행렬을 DataFrame으로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b995e",
   "metadata": {
    "id": "135b995e"
   },
   "source": [
    "---\n",
    "## 4. Sentence Transformer 임베딩 및 유사도 계산\n",
    "\n",
    "**임베딩의 특징:**\n",
    "- 문장 전체를 고정 크기의 밀집 벡터(Dense Vector)로 변환\n",
    "- 문맥과 의미를 이해하여 유사한 의미의 문장은 유사한 벡터 생성\n",
    "- 단어 순서와 문맥을 고려\n",
    "- 계산 비용이 높지만 정확도가 높음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659363c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KURE-v1 모델 로드 (한국어 특화)\n",
    "# 문장들을 벡터로 변환\n",
    "# 첫 번째 문장의 임베딩 벡터 일부 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23c566c",
   "metadata": {
    "id": "d23c566c"
   },
   "source": [
    "### 4.1 임베딩 벡터 기반 유사도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b6d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine_similarity() 사용\n",
    "# 유사도 행렬을 DataFrame으로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f661b4",
   "metadata": {
    "id": "31f661b4"
   },
   "source": [
    "---\n",
    "## 5. 방법론 비교: 단어 매칭 vs 의미 유사도\n",
    "\n",
    "### 5.1 TF-IDF와 임베딩의 차이점 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d693af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 케이스: 의미는 같지만 단어가 다른 문장들\n",
    "    # === TF-IDF 방식 ===\n",
    "    # === 임베딩 방식 ===\n",
    "    # 상세 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb9ad1b",
   "metadata": {
    "id": "4fb9ad1b"
   },
   "source": [
    "---\n",
    "## 6. 학습 정리\n",
    "\n",
    "### 6.1 벡터화 방법 요약\n",
    "\n",
    "| 방법 | 벡터화 함수 | 유사도 계산 함수 | 특징 |\n",
    "|------|------------|----------------|------|\n",
    "| BOW | `CountVectorizer().fit_transform()` | `cosine_similarity()` | 단어 빈도 기반 |\n",
    "| TF-IDF | `TfidfVectorizer().fit_transform()` | `cosine_similarity()` | 단어 중요도 기반 |\n",
    "| 임베딩 | `SentenceTransformer().encode()` | `cosine_similarity()` | 의미 기반 |\n",
    "\n",
    "### 6.2 언제 어떤 방법을 사용할까?\n",
    "\n",
    "| 상황 | 추천 방법 | 이유 |\n",
    "|------|----------|------|\n",
    "| 빠른 키워드 추출 | BOW/TF-IDF | 빠른 처리, 해석 용이 |\n",
    "| 의미 기반 검색 | 임베딩 | 문맥 이해, 유사 의미 인식 |\n",
    "| 대량 문서 처리 (속도 중요) | TF-IDF | 빠른 처리 속도 |\n",
    "| 정확한 의미 분석 (정확도 중요) | 임베딩 | 높은 정확도 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bff272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
